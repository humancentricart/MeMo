{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd95042e-0d56-401d-ae0c-0fbe1eee44e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA RTX A6000 is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac14a52-6180-4c0d-997e-b24745c624f9",
   "metadata": {},
   "source": [
    "## MeMo Tokenizer and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7956914c-ec7b-4fa7-a6a2-dbff28f8cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_tokenizer import MeMoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8673f471-46ce-4875-b74d-e8a0378a01ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPTNeoXTokenizer'. \n",
      "The class this function is called from is 'MeMoTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token and pad token id = <|endoftext|>, 0\n"
     ]
    }
   ],
   "source": [
    "max_length = 12 \n",
    "tokenizer = MeMoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\", \n",
    "                                          truncation_side = 'left',\n",
    "                                          padding_side='left', max_length=max_length, head_number=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c159d5f5-2bf5-4d04-bde2-c897be8f494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[18886,   256, 36144,  4164,  1809,    80,  1448,   295,   532,  1584,\n",
      "            13, 50190]]), tensor([[  256, 36144,  4164,  1809,    80,  1448,   295,   532,  1584,    13,\n",
      "         50190,    15]]))\n"
     ]
    }
   ],
   "source": [
    "with open(\"testo_di_prova.txt\") as my_first_text_f:\n",
    "    my_first_text = my_first_text_f.read()\n",
    "\n",
    "token_ids = tokenizer.encode(my_first_text)#, return_tensors='pt')\n",
    "print(token_ids) # return max len + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c458fb-4eeb-4ffd-91d6-0f22d4d6566f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['input_ids', 'labels']), torch.Size([52, 12]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.get_text_batch_encoding([my_first_text, my_first_text[0:10]])\n",
    "memo_input.keys(), memo_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427781b3-ae1c-430a-b961-6500d44c4100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Cosimo di\n",
      "<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>Cosimo di Giovanni\n",
      "\n",
      " de' Medici detto il Vecchio o Pater\n",
      "' Medici detto il Vecchio o Pater patri\n",
      "\n",
      "æ (Firenze, 27 settembre 1389\n",
      " (Firenze, 27 settembre 1389 –\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(tokenizer.decode(memo_input['input_ids'][i]))\n",
    "    print(tokenizer.decode(memo_input['labels'][i]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb7a04-5b90-48f5-be13-96ca53ce73a7",
   "metadata": {},
   "source": [
    "## MeMo Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e6eeb9-4f10-4fb6-b6c4-53dcfedca561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_embedding import MeMoEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94661fdd-cef9-4a41-b197-9d5f40645e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "d,h,l = 1024, 4, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2612d880-6777-4052-9b05-f32fb1f6dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n"
     ]
    }
   ],
   "source": [
    "embedding = MeMoEmbedding(\n",
    "    num_embeddings=tokenizer.vocab_size,\n",
    "    embedding_dim=d,\n",
    "    padding_idx=tokenizer.pad_token_id, #0\n",
    "    _freeze=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3835b9f2-c1a7-4673-b9a4-ba5710fc0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "         5089],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0, 2447, 6945,  287,\n",
      "         6004]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0582,  0.0155, -0.0178,  ..., -0.0274,  0.0375, -0.0045]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0050, -0.0133,  0.0261,  ...,  0.0378, -0.0316,  0.0230],\n",
       "         [ 0.0376,  0.0051, -0.0028,  ..., -0.0063,  0.0614, -0.0016],\n",
       "         [ 0.0601,  0.0036,  0.0164,  ...,  0.0109, -0.0369, -0.0159]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens_ids = tokenizer(['Test', 'Un altro Test'])['input_ids']\n",
    "print(input_tokens_ids)\n",
    "\n",
    "input_embeddings = embedding.forward(input_tokens_ids)\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf18be91-e462-43c4-adb8-fceb129469e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.get_text_batch_encoding([my_first_text, my_first_text[10:30]])\n",
    "\n",
    "memo_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba11bf1-12c3-4b6e-96e0-7009ffb0d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0, 38577,\n",
       "         17622,  1073],\n",
       "        [  372,     8,  9718,    74,   843,   936,  4164, 43876, 41380,   258,\n",
       "           367,   727],\n",
       "        [ 5507,   313, 15723,   445,  2721,    13,  3435,  3414,   358,  3381,\n",
       "         15410,    26],\n",
       "        [ 9776,  1266,    74,    13,   337, 11703,   639, 39337,  1638,  1540,\n",
       "            10, 12187],\n",
       "        [  440,  2314,  4173,   299,  8913,  2942,   250,   352,  6770,    80,\n",
       "            13,  2248],\n",
       "        [  861,   410,   372, 32924,  1073, 33813,   445,  2721,   299,  2248,\n",
       "            80,  1484],\n",
       "        [ 1073,   659,  4611,  1073,   391,   300,   466,  5711, 14804,  1431,\n",
       "           304, 19702],\n",
       "        [   74,    15, 14929,  1327,  1323, 10081, 24843, 15438,   412, 16406,\n",
       "         38055,  9821],\n",
       "        [ 3737,  1073,   391,   300,   466,  5711, 39814,   260,   770,  5991,\n",
       "           313,  1962],\n",
       "        [18006, 22217, 42722, 10863,   262,  7958,  1593, 12704,  5940,  2719,\n",
       "           538, 21287]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input['input_ids'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59a26e8e-22f3-499a-bba2-f3f714debdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 12, 1024]), torch.Size([52, 12, 1024]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = embedding.encode(memo_input['input_ids'])\n",
    "output_symbols = embedding.encode(memo_input['labels'])\n",
    "\n",
    "input_embeddings.shape, output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3adbd482-ce71-4d86-a049-a9ef8737ee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0, 38577,\n",
       "         17622,  1073],\n",
       "        [  372,     8,  9718,    74,   843,   936,  4164, 43876, 41380,   258,\n",
       "           367,   727],\n",
       "        [ 5507,   313, 15723,   445,  2721,    13,  3435,  3414,   358,  3381,\n",
       "         15410,    26],\n",
       "        [ 9776,  1266,    74,    13,   337, 11703,   639, 39337,  1638,  1540,\n",
       "            10, 12187],\n",
       "        [  440,  2314,  4173,   299,  8913,  2942,   250,   352,  6770,    80,\n",
       "            13,  2248],\n",
       "        [  861,   410,   372, 32924,  1073, 33813,   445,  2721,   299,  2248,\n",
       "            80,  1484],\n",
       "        [ 1073,   659,  4611,  1073,   391,   300,   466,  5711, 14804,  1431,\n",
       "           304, 19702],\n",
       "        [   74,    15, 14929,  1327,  1323, 10081, 24843, 15438,   412, 16406,\n",
       "         38055,  9821],\n",
       "        [ 3737,  1073,   391,   300,   466,  5711, 39814,   260,   770,  5991,\n",
       "           313,  1962],\n",
       "        [18006, 22217, 42722, 10863,   262,  7958,  1593, 12704,  5940,  2719,\n",
       "           538, 21287]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded, _ = embedding.decode(input_embeddings)\n",
    "print(decoded.shape)\n",
    "\n",
    "decoded[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "616e69f2-501c-41fc-8f7e-21b6b3ae2f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded[0:10] == memo_input['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "776eb6ee-c5ec-4b24-afb2-127832d4fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  1.0116, -0.0136,  ..., -0.0119,  0.0133,  0.0027],\n",
       "        [ 0.0000, -0.0136,  0.9932,  ..., -0.0567, -0.0084, -0.0524],\n",
       "        ...,\n",
       "        [ 0.0000, -0.0119, -0.0567,  ...,  1.0161, -0.0105,  0.0283],\n",
       "        [ 0.0000,  0.0133, -0.0084,  ..., -0.0105,  1.0409,  0.0496],\n",
       "        [ 0.0000,  0.0027, -0.0524,  ...,  0.0283,  0.0496,  0.9741]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50247.5547)\n",
      "tensor(-437.1758)\n"
     ]
    }
   ],
   "source": [
    "sims = embedding.weight @ embedding.weight.T\n",
    "display(sims)\n",
    "diag_sum = torch.sum(sims[1:, 1: ].diag()) # almost 1 in each entry\n",
    "print(diag_sum) # obs vs expected\n",
    "print(torch.sum(sims[1:, 1:]) - diag_sum) #almost 0... more or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68109c97-0d07-4737-a2e1-1506927e7897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d65c6b2f-7994-4035-bf57-5e389e6c0db7",
   "metadata": {},
   "source": [
    "## Test layer and MeMo CMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851420e5-b642-4196-9d39-81ec08bbffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_layer import MeMoLayer, ProjectionSequence, ProjectionTokens, CorrelationMatrixMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca806ba1-8230-4e22-8171-a96695a0059c",
   "metadata": {},
   "source": [
    "### Check initialization of each matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6ef81f9-02b6-4236-9542-7ec40f80a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1024]) (trasposed wrt saved one) in_features=4096, out_features=1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([1.0034, 1.0135, 0.9981,  ..., 0.9602, 1.0391, 1.0285],\n",
       "        grad_fn=<DiagonalBackward0_copy>),\n",
       " tensor([0.2335, 0.2499, 0.2359,  ..., 0.2417, 0.2590, 0.2396],\n",
       "        grad_fn=<DiagonalBackward0_copy>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,h,l = 1024, 4, 3\n",
    "proj = ProjectionSequence(d, d*h)\n",
    "print(proj.weight.shape, proj.extra_repr())\n",
    "(proj.weight.T @ proj.weight).diag(), (proj.weight @ proj.weight.T).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b310ff39-9e6c-420e-9062-d83abfa8ef81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.9540, 0.9915, 0.9663,  ..., 0.9823, 1.0174, 1.0255]),\n",
       " tensor([0.2524, 0.2305, 0.2505,  ..., 0.2412, 0.2558, 0.2710]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prj = torch.normal(0, 1/math.sqrt(d*h), size=(d,d*h))\n",
    "Prj = torch.transpose(Prj, 0, 1)\n",
    "(Prj.T @ Prj).diag(), (Prj @ Prj.T).diag()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfe9a656-6558-47a2-a49a-1fcf73865c97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37f1066d-be0d-4772-b06a-4b2cc02fe98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "4\n",
      "torch.Size([256, 1024]) in_features=1024, out_features=256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.9716, 0.8887, 0.9213,  ..., 0.9931, 1.0560, 1.0470],\n",
       "        grad_fn=<DiagonalBackward0_copy>),\n",
       " tensor([3.8957, 3.9282, 3.8173, 3.9242, 3.7240, 4.0538, 4.2113, 3.8914, 4.1052,\n",
       "         4.1155, 4.0357, 3.8291, 4.0179, 4.0468, 4.1695, 3.6141, 3.9338, 3.9435,\n",
       "         4.2316, 3.8034, 4.2810, 3.8362, 3.9516, 4.0251, 3.9569, 4.0409, 4.1122,\n",
       "         3.8379, 3.9411, 4.0859, 4.1653, 4.1817, 4.2582, 3.8627, 3.9495, 3.9011,\n",
       "         3.9367, 4.0767, 3.7587, 3.8176, 3.9241, 3.9176, 3.8721, 4.1166, 3.8814,\n",
       "         4.1041, 4.4408, 3.9817, 4.1150, 4.1030, 4.2362, 4.0798, 3.8293, 3.8891,\n",
       "         3.9857, 4.4485, 4.1655, 3.6626, 4.0928, 3.8111, 3.8579, 3.7830, 3.9901,\n",
       "         3.7101, 4.1409, 4.0890, 3.8550, 4.0866, 4.1738, 3.9588, 4.0144, 4.3011,\n",
       "         4.0719, 3.9803, 3.8962, 4.0984, 4.1461, 4.2218, 3.6977, 4.1242, 3.9939,\n",
       "         4.0745, 4.1220, 4.1001, 3.8201, 3.8617, 3.8810, 3.8470, 4.1705, 4.1657,\n",
       "         3.8939, 3.8102, 4.4850, 3.8803, 4.0308, 3.8671, 3.8971, 3.7658, 3.8068,\n",
       "         3.9323, 3.6949, 3.8368, 4.2517, 4.1453, 4.1490, 4.0823, 3.8388, 3.7740,\n",
       "         4.1057, 4.0059, 3.9543, 4.2601, 4.1098, 3.7778, 4.3126, 3.9319, 4.0853,\n",
       "         3.9642, 4.2576, 3.6678, 4.0273, 3.5869, 4.0748, 3.8786, 4.0148, 4.0289,\n",
       "         3.8545, 4.1845, 3.5423, 4.1684, 4.2942, 4.2512, 3.7922, 3.9931, 3.8749,\n",
       "         4.2715, 3.8800, 4.0412, 4.0067, 4.1811, 4.2883, 3.8510, 4.1339, 3.8761,\n",
       "         3.7544, 4.2321, 4.0032, 3.9000, 3.8973, 4.0645, 3.8875, 3.8104, 3.7593,\n",
       "         4.1655, 3.9774, 3.8623, 3.9143, 4.4477, 3.8193, 3.8739, 3.7454, 4.0288,\n",
       "         4.0185, 3.9098, 4.2056, 4.1742, 4.1869, 3.8858, 4.2583, 4.1845, 4.2469,\n",
       "         3.9608, 4.1746, 3.8862, 4.2633, 4.1130, 3.8765, 4.0957, 4.0908, 3.8670,\n",
       "         3.7088, 3.8760, 4.0690, 4.0604, 3.8614, 3.6620, 4.0636, 3.9518, 3.8478,\n",
       "         4.0245, 4.1239, 4.0842, 4.0488, 3.7557, 3.8848, 4.1753, 4.1091, 3.7693,\n",
       "         3.9207, 3.8181, 4.0585, 4.3876, 3.8558, 4.0011, 3.8530, 3.7305, 3.9086,\n",
       "         4.0004, 3.7873, 3.9459, 3.9987, 4.2158, 3.8779, 3.9086, 4.1297, 3.9616,\n",
       "         4.1150, 4.3063, 3.6843, 3.9161, 3.8839, 4.0430, 4.1310, 3.8242, 3.9952,\n",
       "         3.7405, 3.8971, 4.4978, 3.9798, 3.7885, 4.0290, 3.9788, 3.8599, 3.7306,\n",
       "         3.7792, 3.8929, 3.7450, 4.1551, 3.8557, 3.6486, 4.1222, 4.1144, 4.0577,\n",
       "         3.7377, 4.2149, 4.0281, 3.7843, 4.2591, 4.0761, 4.0457, 3.7766, 4.0458,\n",
       "         3.9618, 4.4041, 4.2812, 4.2170], grad_fn=<DiagonalBackward0_copy>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d)\n",
    "print(h)\n",
    "\n",
    "d_k = d // h\n",
    "\n",
    "W_v = ProjectionTokens(d, d_k)\n",
    "\n",
    "print(W_v.weight.shape, W_v.extra_repr())\n",
    "\n",
    "\n",
    "### always used transposed! so check with .T\n",
    "(W_v.weight.T @ W_v.weight).diag(), (W_v.weight @ W_v.weight.T).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6d736ff-f9d1-4fbf-9f28-5e939fd16192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.0607, 3.9188, 4.1343, 4.3398, 3.9781, 4.0719, 3.9630, 3.9899, 4.1298,\n",
       "         4.0704, 4.1006, 3.5645, 4.1545, 4.2411, 4.3649, 3.8846, 4.0114, 4.1324,\n",
       "         3.9862, 3.8759, 3.9989, 3.9211, 3.7758, 3.6554, 4.1563, 3.9463, 3.8554,\n",
       "         3.7379, 4.1779, 4.1594, 4.2406, 4.0629, 3.8923, 3.6850, 4.0267, 4.1834,\n",
       "         4.0705, 3.9980, 3.9785, 3.6814, 3.8253, 3.9768, 4.1703, 3.5919, 3.7570,\n",
       "         4.1289, 4.1667, 3.6757, 3.9860, 4.0630, 4.1107, 3.8269, 4.0566, 3.9629,\n",
       "         3.8810, 3.9809, 3.8808, 3.9366, 3.6887, 3.7962, 3.9128, 3.6060, 4.1888,\n",
       "         4.0053, 3.8992, 4.1934, 3.9406, 3.9481, 4.0117, 3.9613, 4.0182, 3.7418,\n",
       "         3.9632, 3.9029, 4.2775, 3.7637, 3.9496, 3.9138, 3.8087, 4.0188, 4.0456,\n",
       "         4.1549, 3.9044, 4.1022, 3.7980, 3.9736, 3.9323, 4.2428, 4.1303, 3.8692,\n",
       "         4.0947, 4.3600, 4.2825, 3.8362, 3.9793, 3.9693, 4.0807, 3.7860, 3.7670,\n",
       "         4.0065, 3.9023, 3.7851, 4.0609, 3.9677, 4.1964, 3.6961, 4.0435, 3.7618,\n",
       "         4.1452, 3.9568, 3.9707, 3.6600, 3.8848, 3.9202, 4.0470, 3.8504, 3.9211,\n",
       "         4.2125, 4.1486, 3.9817, 3.9550, 3.9718, 4.2480, 4.1543, 4.0566, 3.8128,\n",
       "         4.3044, 3.8549, 3.8324, 4.0675, 4.1344, 4.0491, 3.7846, 4.0934, 4.0426,\n",
       "         3.9861, 4.1218, 4.0476, 4.3084, 4.1341, 4.1474, 3.9910, 4.1289, 3.9670,\n",
       "         3.8046, 4.0416, 3.7076, 4.2336, 4.2157, 3.9384, 3.9887, 4.3344, 4.1122,\n",
       "         3.6949, 4.1515, 3.9080, 3.8564, 3.8624, 3.7421, 4.1388, 4.1233, 3.7685,\n",
       "         4.0178, 4.0664, 3.7042, 4.1033, 4.0512, 4.0414, 3.8096, 4.0104, 3.9347,\n",
       "         3.6364, 3.8572, 3.9624, 4.0435, 3.6608, 4.2111, 4.2521, 3.7830, 4.2566,\n",
       "         3.9895, 4.2448, 3.6022, 3.9576, 3.8017, 4.1415, 4.0531, 3.9392, 3.9646,\n",
       "         3.9985, 4.2164, 4.1941, 4.1016, 3.7942, 4.1467, 3.9628, 3.7592, 4.0295,\n",
       "         3.7083, 4.0523, 3.8569, 4.0780, 4.0781, 3.9189, 3.9057, 4.1506, 3.7865,\n",
       "         4.0253, 4.1114, 4.1633, 3.8444, 3.9056, 4.1426, 3.9150, 3.9758, 3.9709,\n",
       "         3.8106, 3.9566, 3.9152, 4.2930, 3.6777, 4.0128, 4.0691, 4.0382, 4.0781,\n",
       "         3.9979, 4.0866, 4.0624, 4.0364, 4.1678, 4.1701, 3.9073, 3.9276, 4.0763,\n",
       "         3.8219, 3.9813, 4.2443, 4.1873, 3.9215, 3.9713, 3.9183, 3.7485, 3.7319,\n",
       "         3.9666, 4.0670, 4.0719, 4.1511, 3.8837, 3.9411, 4.0086, 3.8823, 3.9021,\n",
       "         3.8308, 4.0936, 3.7682, 4.1786]),\n",
       " tensor([1.1118, 1.0058, 1.0240,  ..., 1.0348, 0.9914, 1.0014]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_v_single_head = torch.normal(0, 1/math.sqrt(d_k), size=(d,d_k))\n",
    "\n",
    "(W_v_single_head.T @ W_v_single_head).diag(), (W_v_single_head @ W_v_single_head.T).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545596f-fbb2-4e0b-b3f1-1e4f37ebc903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd69212-c26e-4404-95a6-7442d6d814ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ff823bd-ce40-49fd-b67b-5c12dc739614",
   "metadata": {},
   "source": [
    "### Check memorization on single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a33880-0afe-4de6-a594-682be1581cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeMoLayer(\n",
       "  (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "  (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "  (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,h,l = 1024, 4, 3\n",
    "\n",
    "layer = MeMoLayer(d, h)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fdbe2b1-b421-4f7e-8f61-18a82c9b0eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 12, 1024)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, current_length, d = input_embeddings.shape\n",
    "batch_size, current_length, d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7664712d-7ce1-4d64-b1f4-54abb019ffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 12, 1024])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8c91851-c546-48bf-90c6-bb4c7ed5484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4096) torch.Size([4, 1024])\n"
     ]
    }
   ],
   "source": [
    "current_length = int(input_embeddings.shape[1]/ h)\n",
    "\n",
    "input_sequence = input_embeddings.reshape((batch_size, current_length, h, d))\n",
    "\n",
    "current_output_symbols = output_symbols[:, [(x+1)*h-1 for x in range(0,current_length)]]\n",
    "j = 2 \n",
    "print(sum(sum(input_sequence[0][j] == input_embeddings[0][4*j:4*(j+1)])), input_sequence[0][j].shape)\n",
    "\n",
    "(batch_size, blocks,h,d) = input_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99480537-8c54-4dae-85dd-838ce5bfabb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 3, 4, 1024]), torch.Size([52, 3, 1024]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape, current_output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a2ba406-c0a0-4008-9aa0-836372382cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeMoLayer(\n",
       "  (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "  (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "  (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = MeMoLayer(d, h)\n",
    "display(layer)\n",
    "## update the input sequence for the next layer\n",
    "_, seq_encoding_for_the_last_layer = layer.memorize(input_sequence, current_output_symbols, is_last=False)\n",
    "layer.directly_memorize(seq_encoding_for_the_last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c46ccae-66bb-4e72-abaa-b7abdfd0839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 3, 4, 1024]), torch.Size([3, 4, 1024]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape, input_sequence[3].shape # batch (52 elements of chunks 4*4*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8467cfe3-4e46-45ea-b3fc-bac785a84ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 1024])\n"
     ]
    }
   ],
   "source": [
    "_, seq_encoding_for_the_last_layer = layer.retrieve(input_sequence)\n",
    "\n",
    "print(seq_encoding_for_the_last_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a3cd023-37a9-426a-9df2-b7d25a459ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = layer.directly_retrieve(seq_encoding_for_the_last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32a917d5-4a51-4163-9bac-21f960de5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48505, 20110,  1108, 48019,    80, 19216,  9718,  1113,  4927,    66,\n",
      "        19216,  1448,  2122, 41530,   187,  4172,   246,   659, 10986, 30975,\n",
      "           80, 12931,   352, 14134,  2721,   258,  8830,    87,   826,    15,\n",
      "        17532,   729, 26798, 41070,  6575,   299,   266,  3737, 20889,   287,\n",
      "          512,   354,   250,   247,    70,   275, 16128,  2680,    74, 13679,\n",
      "           15,   843]) tensor([0.8819, 1.0156, 0.9961, 0.9514, 1.0413, 1.1477, 1.1566, 0.9515, 1.0465,\n",
      "        1.9006, 1.2682, 0.9832, 1.1472, 1.0905, 1.0196, 1.1548, 1.0398, 0.9599,\n",
      "        0.9555, 1.0387, 1.0676, 1.1081, 1.0265, 1.1388, 1.1526, 1.1123, 0.9653,\n",
      "        1.0188, 1.1298, 0.8249, 1.0822, 1.0452, 0.9774, 0.9335, 0.9042, 0.8819,\n",
      "        1.0207, 0.9899, 1.0153, 1.1080, 0.8006, 0.8810, 0.8329, 1.1565, 1.2493,\n",
      "        0.9081, 1.0114, 0.9514, 1.0136, 1.0880, 0.8588, 1.0223],\n",
      "       grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "retreived_output_symbol_vector, m = embedding.decode(logits)\n",
    "print(retreived_output_symbol_vector, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1acd6b66-770e-42d1-b01a-cce2d9bd2523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48505, 20110,  1108, 48019,    80, 19216,  9718,  1113,  4927,    66,\n",
       "        19216,  1448,  2122, 41530,   187,  4172,   246,   659, 10986, 30975,\n",
       "           80, 12931,   352, 14134,  2721,   258,  8830,    87,   826,    15,\n",
       "        17532,   729, 26798, 41070,  6575,   299,   266,  3737, 20889,   287,\n",
       "          512,   354,   250,   247,    70,   275, 16128,  2680,    74, 13679,\n",
       "           15,   209])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(51) over torch.Size([52])\n"
     ]
    }
   ],
   "source": [
    "o = embedding.decode(current_output_symbols[:, -1])[0]\n",
    "display(o)\n",
    "\n",
    "print(sum(o == retreived_output_symbol_vector), 'over', retreived_output_symbol_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fe7568a-9319-4beb-b56c-89c8fd366f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### test single block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "370fac45-4707-43d5-88f8-df78ee1c931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 1024]) torch.Size([3, 1024])\n",
      "torch.Size([4, 1024]) torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "print(input_sequence[3].shape, current_output_symbols[3].shape)\n",
    "print(input_sequence[3][0].shape, current_output_symbols[3][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d28e7b-29c7-4368-9111-360fd75ab9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01cd5f78-d3a8-4be2-952a-2db537b10110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/156\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0 \n",
    "\n",
    "for batch_index in range(len(memo_input['input_ids'])):\n",
    "    #print(\"input ids\", memo_input[0]['input_ids'][batch_index])\n",
    "    #print()\n",
    "    \n",
    "    for i in range(len(current_output_symbols[batch_index])):\n",
    "        #display(embedding.decode(input_sequence[batch_index][i]), embedding.decode(current_output_symbols[batch_index][i]))\n",
    "        true = embedding.decode(current_output_symbols[batch_index][i])[0].item()\n",
    "        \n",
    "        _, seq_encoding_for_the_last_layer  = layer.retrieve(input_sequence[batch_index][i].unsqueeze(0).unsqueeze(0))\n",
    "        \n",
    "        retreived_output_symbol_vector, m = embedding.decode(layer.directly_retrieve(seq_encoding_for_the_last_layer))\n",
    "        pred = retreived_output_symbol_vector.item()\n",
    "\n",
    "        total += 1\n",
    "        correct += pred == true\n",
    "\n",
    "print(f\"{correct}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592772e2-6b27-4071-bd5f-a441876381fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b22599b-d21d-43bc-b728-dbadd0e4263d",
   "metadata": {},
   "source": [
    "### Check with batch size of 1 and output probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30176822-1cf4-4b5e-8fbc-7e4375fdecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2520,  310,  247, 1071,  323,  247, 1077, 2159, 2159, 3425,  273, 1249]]) tensor([[  310,   247,  1071,   323,   247,  1077,  2159,  2159,  3425,   273,\n",
      "          1249, 21761]])\n",
      "(tensor([[  323,  2159, 21761]]), tensor([[1.0203, 0.9653, 0.9761]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 4, 1024]), torch.Size([1, 3, 1024]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.get_text_batch_encoding(['this is a test for a very short short sequence of 12 tokens'])\n",
    "input_ids, labels = memo_input['input_ids'], memo_input['labels']\n",
    "print(input_ids, labels)\n",
    "\n",
    "input_embeddings = embedding.encode(input_ids)\n",
    "#print(input_embeddings.shape)\n",
    "\n",
    "output_embeddings = embedding.encode(labels)\n",
    "#print(output_embeddings.shape)\n",
    "\n",
    "\n",
    "current_length = max_length\n",
    "\n",
    "current_length = int(current_length/h)\n",
    "input_sequence = input_embeddings.reshape((1, current_length, h, d))\n",
    "\n",
    "output_symbols = output_embeddings[:, [(x+1)*h-1 for x in range(0,current_length)]] ## the output symbol is always the same tokem?\n",
    "print(embedding.decode(output_symbols))\n",
    "input_sequence.shape, output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4968bbc-e2df-44ca-93ac-9610a1ab071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2520,  310,  247, 1071],\n",
       "          [ 323,  247, 1077, 2159],\n",
       "          [2159, 3425,  273, 1249]]]),\n",
       " tensor([[  323,  2159, 21761]]),\n",
       " tensor([[2520,  310,  247, 1071,  323,  247, 1077, 2159, 2159, 3425,  273, 1249]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.decode(input_sequence)[0], embedding.decode(output_symbols)[0], input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cfaf35a-6ff8-4979-9727-cedcb78d8c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 1024])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccc5bed4-5902-4f96-bab2-f1eefe5207c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1024])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "813fecba-8575-4e2b-8271-e94af40c2600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeMoLayer(\n",
       "  (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "  (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "  (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "tensor([323]) tensor([1.0873], grad_fn=<MaxBackward0>)\n",
      "torch.Size([1, 1024])\n",
      "tensor([2159]) tensor([0.9083], grad_fn=<MaxBackward0>)\n",
      "torch.Size([1, 1024])\n",
      "tensor([21761]) tensor([0.9877], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = MeMoLayer(d, h)\n",
    "display(layer)\n",
    "\n",
    "## update the input sequence for the next layer\n",
    "_, seq_encoding_for_the_last_layer = layer.memorize(input_sequence, output_symbols, is_last=False)\n",
    "layer.directly_memorize(seq_encoding_for_the_last_layer)\n",
    "\n",
    "for i in range(0,3):\n",
    "    _, seq_encoding_for_the_last_layer = layer.retrieve(input_sequence[0][i].unsqueeze(0).unsqueeze(0))\n",
    "    print(seq_encoding_for_the_last_layer.shape)\n",
    "                                                        \n",
    "    retreived_output_symbol_vector, m = embedding.decode(layer.directly_retrieve(seq_encoding_for_the_last_layer))\n",
    "    print(retreived_output_symbol_vector, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c89cd-cb85-4742-a214-c1fe1812e0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c3e709-edf1-4366-9766-ed6403ecedb9",
   "metadata": {},
   "source": [
    "## Test the entire MeMo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a73e8f4-a4d6-4dcf-9698-3c9853976b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo import MeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9113cb02-449d-4ff0-b0d4-0cf121004e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_tokenizer import MeMoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a3e1627-b177-455c-9a81-7ab248fb1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testo_di_prova.txt\") as my_first_text_f:\n",
    "    my_first_text = my_first_text_f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c58b7e91-677e-44f4-a738-93b3d3bb9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPTNeoXTokenizer'. \n",
      "The class this function is called from is 'MeMoTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token and pad token id = <|endoftext|>, 0\n"
     ]
    }
   ],
   "source": [
    "max_length = 384\n",
    "print(max_length, h)\n",
    "tokenizer = MeMoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\", \n",
    "                                          padding_side='left', truncation_side='left', \n",
    "                                          max_length=max_length, head_number=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cd21d5d-2e4e-4b8d-aebc-b8f78421a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 384])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.get_text_batch_encoding(my_first_text)\n",
    "memo_input['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bacfc15c-56ea-49e3-9628-cec62cc9019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0' #'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e7021d0-26d9-448b-ba86-23c38c87499c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 4, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,h,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c2b3fb1-8a1c-4678-8831-da82aeece4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeMo(\n",
       "  (encoder): MeMoEmbedding(50254, 1024, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-2): 3 x MeMoLayer(\n",
       "      (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "      (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "      (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MeMo(inner_dim=d, \n",
    "             num_of_heads=h, \n",
    "             num_of_layers=3, \n",
    "             chunk_length=max_length, \n",
    "             num_embeddings=tokenizer.vocab_size, \n",
    "             padding_idx=tokenizer.pad_token_id, \n",
    "             device=device) #MeMoModel\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "850ad4cc-61c2-45f3-bcf3-2114468331bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 384, 1024]), torch.Size([2, 384, 1024]), 384)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence =  model.encoder.encode(memo_input['input_ids'])\n",
    "output_symbols = model.encoder.encode(memo_input['labels'])\n",
    "\n",
    "(batch_size, current_length, d) = input_sequence.shape\n",
    "last_layer = model.layers[model.l-1]\n",
    "\n",
    "current_length = model.chunk_length\n",
    "\n",
    "input_sequence.shape, output_symbols.shape, current_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6c1208c5-8186-4740-8d3c-65b57a792cbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3], [1, 2, 3, 4], [2, 3, 4, 5], [3, 4, 5, 6], [4, 5, 6, 7]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_level = 0\n",
    "input_index = [[j for j in range(i - model.h ** (layer_level + 1), i, model.h ** ((layer_level + 1) - 1))] \n",
    "               for i in range(model.h ** (layer_level + 1), current_length + 1)]\n",
    "input_index[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f8d5d83c-8633-49c3-ac64-83088339792b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 384, 1024]), torch.Size([2, 384, 1024]))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_input_seq = torch.clone(input_sequence)\n",
    "original_out = torch.clone(output_symbols)\n",
    "\n",
    "original_input_seq.shape, original_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e689a9e-ab03-41eb-9fc6-832c6f95080f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81da7dce-28c9-4dcf-a6ba-3f7ea6a0ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "torch.Size([2, 381, 1024])\n",
      "torch.Size([2, 381, 4, 1024])\n"
     ]
    }
   ],
   "source": [
    "#for layer_level in range(model.l):\n",
    "layer_level = 0 #1,2\n",
    "          \n",
    "print(model.h ** (layer_level + 1) < current_length + 1)\n",
    "## update the input sequence for the next layer\n",
    "layer_output_idxs = [i - model.h ** ((layer_level + 1) - 1) for i in range(model.h ** (layer_level + 1), current_length + 1)]\n",
    "output_symbols = output_symbols[:, layer_output_idxs]\n",
    "print(output_symbols.shape)\n",
    "\n",
    "input_index = [[j for j in range(i - model.h ** (layer_level + 1), i, model.h ** ((layer_level + 1) - 1))] \n",
    "               for i in range(model.h ** (layer_level + 1), current_length + 1)]\n",
    "\n",
    "\n",
    "input_sequence = input_sequence[:, input_index]\n",
    "print(input_sequence.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68743a34-c4ff-46ed-82e1-e319cd3391b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True], device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encoder.decode(output_symbols[0])[0] == model.encoder.decode(torch.stack([original_out[0][i] for i in layer_output_idxs]))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19285dec-a99a-419b-85c8-22985b57a009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c237394a-cb47-413a-bac2-5a52333b243d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2a7f82-162f-4089-add0-bdf07295d30a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b74e5e8f-2f0e-4838-87ca-3a55ae3b8081",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "    def check_memorization(self, model, tokenizer, text, # device='cpu',\n",
    "                           starting_point=None):\n",
    "        if starting_point == None:\n",
    "            basic_block = model.h ** model.l\n",
    "        else:\n",
    "            basic_block = starting_point\n",
    "        \n",
    "        \n",
    "        input_ = tokenizer(my_first_text, padding='longest', truncation='do_not_truncate', max_length=None)\n",
    "        input_ = tokenizer.pad(input_, pad_to_multiple_of=basic_block)\n",
    "        input_ids = input_['input_ids']\n",
    "                \n",
    "        count = 0\n",
    "        correct = 0\n",
    "        max_length = tokenizer.max_length\n",
    "        (batch_size, number_of_tokens) = input_ids.shape\n",
    "\n",
    "        #print(f\"(batch_size, number_of_tokens) = {(batch_size, number_of_tokens)}\")\n",
    "        \n",
    "        for i in tqdm.tqdm(range(basic_block,  number_of_tokens - 1)):\n",
    "            text_tokens = input_ids[:, i - basic_block:i]\n",
    "            \n",
    "            (batch_size, number_of_tokens) = text_tokens.shape\n",
    "            \n",
    "            text_tokens = torch.concat((torch.zeros((batch_size, max_length-1-number_of_tokens), \n",
    "                                                    dtype=torch.int), \n",
    "                                        text_tokens), axis=1\n",
    "                                      )\n",
    "            \n",
    "            #print(i - basic_block, i)\n",
    "            out, max_value = model.retrieve(text_tokens)\n",
    "            #print(out, input_ids[:, i])\n",
    "            #print(out[0].item())\n",
    "            \n",
    "            count += batch_size\n",
    "            correct += torch.sum(out.to('cpu') == input_ids[:, i])\n",
    "        \n",
    "                           \n",
    "        return correct / count\n",
    "\n",
    "    def check_pretokenized(self, model, tokenizer, input_ids,# device='cpu',\n",
    "                           starting_point=None):\n",
    "        if starting_point == None:\n",
    "            basic_block = model.h ** model.l\n",
    "        else:\n",
    "            basic_block = starting_point\n",
    "                \n",
    "        count = 0\n",
    "        correct = 0\n",
    "        max_length = tokenizer.max_length\n",
    "        (batch_size, number_of_tokens) = input_ids.shape\n",
    "\n",
    "        #print(f\"(batch_size, number_of_tokens) = {(batch_size, number_of_tokens)}\")\n",
    "        \n",
    "        for i in tqdm.tqdm(range(basic_block,  number_of_tokens - 1)):\n",
    "            text_tokens = input_ids[:, i - basic_block:i]\n",
    "            \n",
    "            (batch_size, number_of_tokens) = text_tokens.shape\n",
    "            \n",
    "            text_tokens = torch.concat((torch.zeros((batch_size, max_length-1-number_of_tokens), \n",
    "                                                    dtype=torch.int), \n",
    "                                        text_tokens), axis=1\n",
    "                                      )\n",
    "            \n",
    "            #print(i - basic_block, i)\n",
    "            out, max_value = model.retrieve(text_tokens)\n",
    "            #print(out, input_ids[:, i])\n",
    "            #print(out[0].item())\n",
    "            \n",
    "            count += batch_size\n",
    "            correct += torch.sum(out.to('cpu') == input_ids[:, i])\n",
    "        \n",
    "                           \n",
    "        return correct / count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f8a2bd82-a24f-4274-a2bf-26170f8abfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 384])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MeMo(inner_dim=d, \n",
    "             num_of_heads=h, \n",
    "             num_of_layers=l, \n",
    "             chunk_length=max_length, \n",
    "             num_embeddings=tokenizer.vocab_size, \n",
    "             padding_idx=tokenizer.pad_token_id, \n",
    "             device=device)\n",
    "\n",
    "memo_input = tokenizer.get_text_batch_encoding([my_first_text]*8)\n",
    "\n",
    "\n",
    "memo_input['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0a856-4f26-40da-b600-fc8b2bdbe7b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bca7a003-745f-418d-96c0-9f02bc9cce3a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.memorize_text(memo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c12ee0c6-1d8e-402c-9078-17ae941c9ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:00<00:00, 746.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.8448)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "e = Evaluation()\n",
    "out = e.check_pretokenized(model, tokenizer, memo_input['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f431f7b1-27ac-4f7f-a476-d8f61102de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forget_text(memo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "186d2b13-ace1-4bee-9591-b6f5530e0a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:00<00:00, 763.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.0815)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = e.check_pretokenized(model, tokenizer, memo_input['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c72f7371-61f8-4f80-b332-ec7d8703d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n",
      "CMM pre learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n",
      "torch.Size([2, 384])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:00<00:00, 792.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.9624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MeMo(inner_dim=d, \n",
    "             num_of_heads=h, \n",
    "             num_of_layers=l, \n",
    "             chunk_length=max_length, \n",
    "             num_embeddings=tokenizer.vocab_size, \n",
    "             padding_idx=tokenizer.pad_token_id, \n",
    "             device=device)\n",
    "print(\"CMM pre learning\")\n",
    "display(model.layers[0].CMM.weight)\n",
    "\n",
    "\n",
    "bs = 8\n",
    "for b in range(bs):\n",
    "    memo_input = tokenizer.get_text_batch_encoding(my_first_text)\n",
    "    print(memo_input['input_ids'].shape)\n",
    "\n",
    "    model.memorize_text(memo_input)\n",
    "\n",
    "e = Evaluation()\n",
    "out = e.check_pretokenized(model, tokenizer, memo_input['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "67c1f7ed-02cd-4f13-aa01-e8821b11f302",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.4733e-01,  6.2101e-04, -8.6885e-03,  ..., -8.4878e-03,\n",
       "          1.7844e-02,  1.2130e-02],\n",
       "        [ 6.2101e-04,  1.0110e+00, -2.2606e-02,  ..., -1.0224e-02,\n",
       "         -1.9795e-02,  8.5904e-03],\n",
       "        [-8.6885e-03, -2.2606e-02,  9.6828e-01,  ...,  1.8914e-02,\n",
       "         -3.0991e-03,  2.6482e-02],\n",
       "        ...,\n",
       "        [-8.4878e-03, -1.0224e-02,  1.8914e-02,  ...,  1.0126e+00,\n",
       "         -2.0454e-02,  2.7226e-03],\n",
       "        [ 1.7844e-02, -1.9795e-02, -3.0991e-03,  ..., -2.0454e-02,\n",
       "          1.0351e+00, -6.7074e-03],\n",
       "        [ 1.2130e-02,  8.5904e-03,  2.6482e-02,  ...,  2.7226e-03,\n",
       "         -6.7074e-03,  1.0019e+00]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prj = model.layers[0].Prj.weight.detach().cpu()\n",
    "CMM = model.layers[0].CMM.weight.detach().cpu()\n",
    "\n",
    "Prj.T @ Prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "41935a13-0b0f-4b93-b129-0a1e88241fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0060,  0.0329, -0.0196,  ..., -0.0565,  0.0308, -0.0099],\n",
       "        [-0.0205, -0.0693, -0.0293,  ...,  0.0095, -0.0060,  0.0002],\n",
       "        [-0.0252, -0.0445, -0.0202,  ...,  0.0301,  0.0368,  0.0085],\n",
       "        ...,\n",
       "        [ 0.0099,  0.0281, -0.0018,  ..., -0.0022,  0.0010,  0.0280],\n",
       "        [-0.0315, -0.0133, -0.0283,  ...,  0.0207,  0.0575, -0.0010],\n",
       "        [-0.0069,  0.0160,  0.0095,  ...,  0.0081,  0.0150, -0.0087]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d237416-54ea-4b21-8d19-84599ff9e34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8ad99bb2-af43-4e42-a447-6871f4ee47f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:00<00:00, 802.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.9624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = e.check_pretokenized(model, tokenizer, memo_input['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "346e794d-b1c9-438e-b66f-14fd17c1ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forget_text(memo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c4d5e5c-a117-4378-970a-d42b76a0ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:00<00:00, 799.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.9624)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = e.check_pretokenized(model, tokenizer, memo_input['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9e371-c48a-479a-8cec-fc87c9aaacdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
