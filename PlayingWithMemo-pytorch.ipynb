{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd95042e-0d56-401d-ae0c-0fbe1eee44e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU: NVIDIA RTX A6000 is available.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)} is available.\")\n",
    "else:\n",
    "    print(\"No GPU available. Training will run on CPU.\")\n",
    "\n",
    "verbose = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac14a52-6180-4c0d-997e-b24745c624f9",
   "metadata": {},
   "source": [
    "## MeMo Tokenizer and input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7956914c-ec7b-4fa7-a6a2-dbff28f8cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_tokenizer import MeMoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8673f471-46ce-4875-b74d-e8a0378a01ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPTNeoXTokenizer'. \n",
      "The class this function is called from is 'MeMoTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token and pad token id = <|endoftext|>, 0\n"
     ]
    }
   ],
   "source": [
    "max_length = 12 \n",
    "tokenizer = MeMoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\", \n",
    "                                          truncation_side = 'left',\n",
    "                                          padding_side='left', max_length=max_length, head_number=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c159d5f5-2bf5-4d04-bde2-c897be8f494f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[18886,   256, 36144,  4164,  1809,    80,  1448,   295,   532,  1584,\n",
      "            13, 50190]]), tensor([[  256, 36144,  4164,  1809,    80,  1448,   295,   532,  1584,    13,\n",
      "         50190,    15]]))\n"
     ]
    }
   ],
   "source": [
    "with open(\"testo_di_prova.txt\") as my_first_text_f:\n",
    "    my_first_text = my_first_text_f.read()\n",
    "\n",
    "token_ids = tokenizer.encode(my_first_text)#, return_tensors='pt')\n",
    "print(token_ids) # return max len + 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32c458fb-4eeb-4ffd-91d6-0f22d4d6566f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.get_text_batch_encoding([my_first_text, my_first_text[0:10]])\n",
    "memo_input.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "427781b3-ae1c-430a-b961-6500d44c4100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 12])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb7a04-5b90-48f5-be13-96ca53ce73a7",
   "metadata": {},
   "source": [
    "## MeMo Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3e6eeb9-4f10-4fb6-b6c4-53dcfedca561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_embedding import MeMoEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94661fdd-cef9-4a41-b197-9d5f40645e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "d,h,l = 1024, 4, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2612d880-6777-4052-9b05-f32fb1f6dec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n"
     ]
    }
   ],
   "source": [
    "embedding = MeMoEmbedding(\n",
    "    num_embeddings=tokenizer.vocab_size,\n",
    "    embedding_dim=d,\n",
    "    padding_idx=tokenizer.pad_token_id, #0\n",
    "    _freeze=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3835b9f2-c1a7-4673-b9a4-ba5710fc0df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "         5089],\n",
      "        [   0,    0,    0,    0,    0,    0,    0,    0,    0, 2447, 6945,  287,\n",
      "         6004]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [-0.0161,  0.0099, -0.0306,  ..., -0.0136,  0.0123, -0.0044]],\n",
       "\n",
       "        [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "         ...,\n",
       "         [ 0.0047,  0.0229,  0.0024,  ..., -0.0326,  0.0234, -0.0191],\n",
       "         [-0.0210, -0.0099,  0.0065,  ...,  0.0447, -0.0401,  0.0088],\n",
       "         [-0.0516,  0.0538,  0.0633,  ..., -0.0263,  0.0363, -0.0175]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tokens_ids = tokenizer(['Test', 'Un altro Test'])['input_ids']\n",
    "print(input_tokens_ids)\n",
    "\n",
    "input_embeddings = embedding.forward(input_tokens_ids)\n",
    "input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf18be91-e462-43c4-adb8-fceb129469e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 12])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.get_text_batch_encoding([my_first_text, my_first_text[10:30]])\n",
    "\n",
    "memo_input[0]['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba11bf1-12c3-4b6e-96e0-7009ffb0d60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0, 38577,\n",
       "         17622,  1073],\n",
       "        [  372,     8,  9718,    74,   843,   936,  4164, 43876, 41380,   258,\n",
       "           367,   727],\n",
       "        [ 5507,   313, 15723,   445,  2721,    13,  3435,  3414,   358,  3381,\n",
       "         15410,    26],\n",
       "        [ 9776,  1266,    74,    13,   337, 11703,   639, 39337,  1638,  1540,\n",
       "            10, 12187],\n",
       "        [  440,  2314,  4173,   299,  8913,  2942,   250,   352,  6770,    80,\n",
       "            13,  2248],\n",
       "        [  861,   410,   372, 32924,  1073, 33813,   445,  2721,   299,  2248,\n",
       "            80,  1484],\n",
       "        [ 1073,   659,  4611,  1073,   391,   300,   466,  5711, 14804,  1431,\n",
       "           304, 19702],\n",
       "        [   74,    15, 14929,  1327,  1323, 10081, 24843, 15438,   412, 16406,\n",
       "         38055,  9821],\n",
       "        [ 3737,  1073,   391,   300,   466,  5711, 39814,   260,   770,  5991,\n",
       "           313,  1962],\n",
       "        [18006, 22217, 42722, 10863,   262,  7958,  1593, 12704,  5940,  2719,\n",
       "           538, 21287]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input[0]['input_ids'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59a26e8e-22f3-499a-bba2-f3f714debdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 12, 1024]), torch.Size([52, 12, 1024]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_embeddings = embedding.encode(memo_input[0]['input_ids'])\n",
    "output_symbols = embedding.encode(memo_input[0]['labels'])\n",
    "\n",
    "input_embeddings.shape, output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3adbd482-ce71-4d86-a049-a9ef8737ee31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     0,     0,     0,     0,     0,     0,     0,     0, 38577,\n",
       "         17622,  1073],\n",
       "        [  372,     8,  9718,    74,   843,   936,  4164, 43876, 41380,   258,\n",
       "           367,   727],\n",
       "        [ 5507,   313, 15723,   445,  2721,    13,  3435,  3414,   358,  3381,\n",
       "         15410,    26],\n",
       "        [ 9776,  1266,    74,    13,   337, 11703,   639, 39337,  1638,  1540,\n",
       "            10, 12187],\n",
       "        [  440,  2314,  4173,   299,  8913,  2942,   250,   352,  6770,    80,\n",
       "            13,  2248],\n",
       "        [  861,   410,   372, 32924,  1073, 33813,   445,  2721,   299,  2248,\n",
       "            80,  1484],\n",
       "        [ 1073,   659,  4611,  1073,   391,   300,   466,  5711, 14804,  1431,\n",
       "           304, 19702],\n",
       "        [   74,    15, 14929,  1327,  1323, 10081, 24843, 15438,   412, 16406,\n",
       "         38055,  9821],\n",
       "        [ 3737,  1073,   391,   300,   466,  5711, 39814,   260,   770,  5991,\n",
       "           313,  1962],\n",
       "        [18006, 22217, 42722, 10863,   262,  7958,  1593, 12704,  5940,  2719,\n",
       "           538, 21287]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded, _ = embedding.decode(input_embeddings)\n",
    "print(decoded.shape)\n",
    "\n",
    "decoded[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "616e69f2-501c-41fc-8f7e-21b6b3ae2f9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded[0:10] == memo_input[0]['input_ids'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "776eb6ee-c5ec-4b24-afb2-127832d4fc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.9347, -0.0361,  ...,  0.0141, -0.0392, -0.0228],\n",
       "        [ 0.0000, -0.0361,  1.0207,  ...,  0.0225,  0.0086, -0.0225],\n",
       "        ...,\n",
       "        [ 0.0000,  0.0141,  0.0225,  ...,  1.0130, -0.0314, -0.0594],\n",
       "        [ 0.0000, -0.0392,  0.0086,  ..., -0.0314,  0.9786, -0.0431],\n",
       "        [ 0.0000, -0.0228, -0.0225,  ..., -0.0594, -0.0431,  0.9813]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50260.8867)\n",
      "tensor(-2720.1641)\n"
     ]
    }
   ],
   "source": [
    "sims = embedding.weight @ embedding.weight.T\n",
    "display(sims)\n",
    "diag_sum = torch.sum(sims[1:, 1: ].diag()) # almost 1 in each entry\n",
    "print(diag_sum) # obs vs expected\n",
    "print(torch.sum(sims[1:, 1:]) - diag_sum) #almost 0... more or less"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68109c97-0d07-4737-a2e1-1506927e7897",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d65c6b2f-7994-4035-bf57-5e389e6c0db7",
   "metadata": {},
   "source": [
    "## Test layer and MeMo CMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "851420e5-b642-4196-9d39-81ec08bbffa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_layer import MeMoLayer, ProjectionSequence, ProjectionTokens, CorrelationMatrixMemory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca806ba1-8230-4e22-8171-a96695a0059c",
   "metadata": {},
   "source": [
    "### Check initialization of each matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6ef81f9-02b6-4236-9542-7ec40f80a333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096, 1024]) (trasposed wrt saved one) in_features=4096, out_features=1024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.9743, 0.9976, 0.9968,  ..., 0.9491, 1.0334, 1.0173],\n",
       "        grad_fn=<DiagonalBackward0_copy>),\n",
       " tensor([0.2565, 0.2527, 0.2624,  ..., 0.2417, 0.2660, 0.2444],\n",
       "        grad_fn=<DiagonalBackward0_copy>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,h,l = 1024, 4, 3\n",
    "proj = ProjectionSequence(d, d*h)\n",
    "print(proj.weight.shape, proj.extra_repr())\n",
    "(proj.weight.T @ proj.weight).diag(), (proj.weight @ proj.weight.T).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b310ff39-9e6c-420e-9062-d83abfa8ef81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.0152, 0.9706, 0.9694,  ..., 0.9638, 0.9894, 1.0372]),\n",
       " tensor([0.2450, 0.2314, 0.2501,  ..., 0.2391, 0.2572, 0.2516]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prj = torch.normal(0, 1/math.sqrt(d*h), size=(d,d*h))\n",
    "Prj = torch.transpose(Prj, 0, 1)\n",
    "(Prj.T @ Prj).diag(), (Prj @ Prj.T).diag()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfe9a656-6558-47a2-a49a-1fcf73865c97",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37f1066d-be0d-4772-b06a-4b2cc02fe98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024\n",
      "4\n",
      "torch.Size([256, 1024]) in_features=1024, out_features=256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([0.9536, 0.9282, 0.8832,  ..., 0.9966, 0.8963, 0.9501],\n",
       "        grad_fn=<DiagonalBackward0_copy>),\n",
       " tensor([3.9666, 4.0939, 4.2988, 4.0052, 4.1969, 4.2777, 4.1574, 4.1704, 3.7788,\n",
       "         4.3970, 3.9970, 4.1488, 3.8178, 3.9645, 3.8420, 4.0947, 3.9161, 4.2043,\n",
       "         3.6926, 4.0570, 4.1142, 3.7652, 4.0730, 3.8482, 4.0229, 3.8988, 3.7216,\n",
       "         4.0209, 4.0156, 3.9800, 4.0440, 4.2623, 4.0462, 3.8154, 3.7813, 4.0432,\n",
       "         3.8823, 3.8828, 3.8986, 3.9567, 3.8791, 4.2087, 4.1604, 3.9781, 3.9351,\n",
       "         4.1483, 3.8459, 3.9146, 3.9400, 4.1593, 3.9039, 3.9640, 4.0969, 3.7689,\n",
       "         4.1690, 3.8867, 4.3060, 4.0505, 3.9825, 3.9963, 3.9738, 4.0899, 3.9403,\n",
       "         3.8676, 4.1243, 4.3099, 4.0107, 3.7395, 3.7215, 3.9500, 3.7980, 3.9023,\n",
       "         3.9330, 4.0665, 4.0252, 4.1403, 4.0016, 3.8523, 3.7321, 3.9791, 4.4043,\n",
       "         3.8752, 3.9721, 4.0179, 3.8165, 3.8789, 4.0939, 4.0955, 3.8693, 4.2991,\n",
       "         4.1217, 4.0396, 3.6650, 4.0047, 4.0859, 4.0621, 4.0245, 4.0620, 3.9047,\n",
       "         4.1656, 3.7512, 3.9442, 4.1193, 3.9230, 4.0075, 4.2080, 3.7937, 4.0003,\n",
       "         3.9821, 3.9224, 4.0137, 3.9584, 3.9980, 3.9038, 3.7891, 3.7588, 3.8625,\n",
       "         4.0130, 3.7875, 4.0072, 3.8766, 4.2756, 3.8634, 4.0950, 3.6932, 3.9262,\n",
       "         4.2843, 4.0519, 4.0599, 3.9607, 4.1437, 4.3940, 3.8133, 3.8640, 3.9927,\n",
       "         3.8388, 4.0543, 3.9061, 3.7415, 4.1347, 4.1258, 3.9204, 4.0846, 3.9674,\n",
       "         3.6930, 4.0264, 3.7433, 3.9510, 4.1000, 4.0619, 4.1971, 4.0783, 3.6890,\n",
       "         3.9478, 4.1952, 3.9597, 3.8303, 4.1318, 4.0995, 3.7921, 4.0279, 4.0003,\n",
       "         3.8440, 3.8640, 4.2099, 4.3302, 4.4913, 4.1889, 3.9964, 4.2255, 3.7754,\n",
       "         3.9073, 4.0997, 3.7236, 3.7461, 4.2391, 4.0381, 3.9395, 4.1121, 4.1406,\n",
       "         3.7544, 3.8009, 3.8532, 3.9085, 3.7001, 3.8536, 4.1642, 3.9917, 3.9694,\n",
       "         4.0210, 3.9069, 4.2003, 4.2605, 4.0769, 4.0432, 3.9888, 4.3248, 4.0239,\n",
       "         3.9063, 4.1181, 4.0973, 3.8766, 3.9507, 3.9617, 3.8989, 4.3126, 3.9259,\n",
       "         3.9601, 4.0444, 4.1210, 3.9924, 4.0240, 3.9724, 4.2061, 4.1734, 4.1076,\n",
       "         4.2047, 4.2000, 4.0336, 4.0110, 3.6836, 4.0261, 4.0799, 4.0609, 3.7753,\n",
       "         4.1834, 3.8447, 4.2341, 3.6250, 4.0310, 4.0076, 4.2672, 4.0590, 3.7968,\n",
       "         3.9131, 4.0061, 4.0058, 4.2386, 4.2879, 4.1406, 3.9371, 4.1687, 3.7247,\n",
       "         4.1836, 4.0683, 3.8849, 3.8391, 3.9973, 4.2114, 4.2818, 3.9325, 3.6086,\n",
       "         3.8429, 4.1653, 4.0669, 3.7385], grad_fn=<DiagonalBackward0_copy>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d)\n",
    "print(h)\n",
    "\n",
    "d_k = d // h\n",
    "\n",
    "W_v = ProjectionTokens(d, d_k)\n",
    "\n",
    "print(W_v.weight.shape, W_v.extra_repr())\n",
    "\n",
    "\n",
    "### always used transposed! so check with .T\n",
    "(W_v.weight.T @ W_v.weight).diag(), (W_v.weight @ W_v.weight.T).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6d736ff-f9d1-4fbf-9f28-5e939fd16192",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3.9115, 3.8792, 4.3531, 3.9076, 4.0819, 3.9219, 3.7893, 3.8794, 4.2437,\n",
       "         3.7041, 4.3074, 4.0168, 4.0283, 3.7861, 3.9509, 4.0091, 3.9561, 3.9187,\n",
       "         3.8834, 3.7614, 3.8834, 3.7877, 3.7784, 3.9032, 4.0129, 4.1955, 4.0918,\n",
       "         3.9693, 4.1765, 4.0418, 3.9616, 3.9822, 3.9425, 4.1296, 3.8702, 3.8956,\n",
       "         4.0325, 4.0417, 3.8514, 3.7178, 3.9856, 4.0762, 4.0763, 4.2492, 4.1772,\n",
       "         4.0986, 4.0013, 3.9240, 4.1282, 3.9898, 4.3139, 4.0509, 3.7595, 4.2079,\n",
       "         3.8705, 4.3164, 3.9169, 3.5837, 4.1498, 3.8917, 4.0558, 3.8311, 3.8746,\n",
       "         4.3504, 4.1333, 4.0077, 4.1311, 3.9522, 4.0267, 4.0657, 4.3141, 4.3397,\n",
       "         3.8193, 3.7877, 4.0753, 4.1815, 4.0575, 3.9062, 3.8312, 4.1112, 4.0141,\n",
       "         3.7511, 4.1266, 3.6544, 4.3672, 4.0148, 4.0176, 3.8992, 3.9791, 3.9479,\n",
       "         3.9572, 4.0422, 3.8299, 4.1287, 4.1621, 4.1473, 4.3931, 3.9538, 4.2009,\n",
       "         3.7590, 3.9368, 4.1343, 3.8517, 4.2789, 4.0345, 3.6222, 4.1233, 3.8122,\n",
       "         3.9075, 4.0444, 3.9615, 4.2387, 3.8410, 4.1951, 4.2030, 4.1990, 4.1595,\n",
       "         4.1561, 4.2732, 4.2968, 3.9024, 3.9330, 3.9029, 4.0533, 3.6161, 4.0148,\n",
       "         4.0236, 3.9668, 3.7556, 4.1876, 4.0187, 3.8889, 4.2267, 3.7240, 4.0145,\n",
       "         3.8062, 3.8375, 3.8359, 4.0325, 4.2509, 4.1517, 3.8272, 3.9099, 3.9065,\n",
       "         4.2415, 4.1141, 4.1498, 3.7887, 3.8498, 3.9884, 4.0042, 3.8421, 3.8707,\n",
       "         3.8115, 3.9848, 4.0257, 3.6512, 3.8629, 4.1909, 4.0833, 4.0775, 3.9495,\n",
       "         4.0022, 4.0096, 3.9794, 3.8603, 4.1647, 3.8261, 4.0680, 4.1223, 4.1155,\n",
       "         3.8578, 3.9878, 4.1575, 3.8551, 4.0188, 4.0517, 3.8550, 4.3904, 4.0534,\n",
       "         4.1058, 3.9838, 3.6603, 3.9771, 4.1348, 4.2485, 3.9273, 4.0222, 4.0120,\n",
       "         4.0051, 3.8479, 4.0865, 3.7853, 4.1021, 3.9339, 3.7919, 3.9627, 4.0249,\n",
       "         3.9317, 4.1948, 3.8272, 4.0333, 4.0174, 3.9680, 4.1450, 3.8974, 3.7800,\n",
       "         4.2513, 4.0589, 3.8626, 4.0308, 4.2041, 4.1996, 3.9126, 4.4110, 3.8473,\n",
       "         3.9238, 3.7816, 3.9316, 3.5459, 4.1658, 3.8120, 3.8561, 4.2109, 4.1455,\n",
       "         4.0258, 4.0792, 4.0416, 3.9542, 3.5760, 3.6994, 4.0945, 3.8587, 4.1469,\n",
       "         3.9543, 4.1434, 3.8724, 3.7975, 3.6866, 3.9993, 3.7645, 3.9097, 3.9880,\n",
       "         4.0176, 3.9449, 4.0026, 3.9661, 3.8000, 4.1072, 4.1554, 4.0135, 4.3025,\n",
       "         3.9960, 3.7605, 4.0251, 3.9063]),\n",
       " tensor([1.1575, 0.8607, 1.0630,  ..., 1.0680, 0.9759, 0.9630]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_v_single_head = torch.normal(0, 1/math.sqrt(d_k), size=(d,d_k))\n",
    "\n",
    "(W_v_single_head.T @ W_v_single_head).diag(), (W_v_single_head @ W_v_single_head.T).diag()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c545596f-fbb2-4e0b-b3f1-1e4f37ebc903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd69212-c26e-4404-95a6-7442d6d814ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3ff823bd-ce40-49fd-b67b-5c12dc739614",
   "metadata": {},
   "source": [
    "### Check memorization on single layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10a33880-0afe-4de6-a594-682be1581cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeMoLayer(\n",
       "  (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "  (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "  (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,h,l = 1024, 4, 3\n",
    "\n",
    "layer = MeMoLayer(d, h)\n",
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6fdbe2b1-b421-4f7e-8f61-18a82c9b0eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 12, 1024)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, current_length, d = input_embeddings.shape\n",
    "batch_size, current_length, d "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7664712d-7ce1-4d64-b1f4-54abb019ffee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([52, 12, 1024])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8c91851-c546-48bf-90c6-bb4c7ed5484c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4096) torch.Size([4, 1024])\n"
     ]
    }
   ],
   "source": [
    "current_length = int(input_embeddings.shape[1]/ h)\n",
    "\n",
    "input_sequence = input_embeddings.reshape((batch_size, current_length, h, d))\n",
    "\n",
    "current_output_symbols = output_symbols[:, [(x+1)*h-1 for x in range(0,current_length)]]\n",
    "j = 2 \n",
    "print(sum(sum(input_sequence[0][j] == input_embeddings[0][4*j:4*(j+1)])), input_sequence[0][j].shape)\n",
    "\n",
    "(batch_size, blocks,h,d) = input_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "99480537-8c54-4dae-85dd-838ce5bfabb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 3, 4, 1024]), torch.Size([52, 3, 1024]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape, current_output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a2ba406-c0a0-4008-9aa0-836372382cca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeMoLayer(\n",
       "  (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "  (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "  (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layer = MeMoLayer(d, h)\n",
    "display(layer)\n",
    "## update the input sequence for the next layer\n",
    "_, seq_encoding_for_the_last_layer = layer.memorize(input_sequence, current_output_symbols, is_last=False)\n",
    "layer.directly_memorize(seq_encoding_for_the_last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c46ccae-66bb-4e72-abaa-b7abdfd0839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([52, 3, 4, 1024]), torch.Size([3, 4, 1024]))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape, input_sequence[3].shape # batch (52 elements of chunks 4*4*1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8467cfe3-4e46-45ea-b3fc-bac785a84ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([52, 1024])\n"
     ]
    }
   ],
   "source": [
    "_, seq_encoding_for_the_last_layer = layer.retrieve(input_sequence)\n",
    "\n",
    "print(seq_encoding_for_the_last_layer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a3cd023-37a9-426a-9df2-b7d25a459ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = layer.directly_retrieve(seq_encoding_for_the_last_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32a917d5-4a51-4163-9bac-21f960de5290",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([48505, 20110,  1108, 48019,    80, 19216,  9718,  1113,  4927,    66,\n",
      "        19216,  1448,  2122, 41530,   187,  4172,   246,   659, 10986, 30975,\n",
      "           80, 12931,   352, 14134,  2721,   258,  8830,    87,   826,    15,\n",
      "        17532,   729, 26798, 41070,  6575,   299,   266,  3737, 20889,   287,\n",
      "          512,   354,   250,   247,    70,   275, 16128,  2680,    74, 13679,\n",
      "           15,   209]) tensor([0.6741, 0.9087, 0.9506, 1.0715, 1.0061, 1.3768, 1.0262, 1.0275, 1.0287,\n",
      "        1.6682, 1.2615, 0.9422, 1.1550, 0.9810, 0.9824, 1.0470, 1.0436, 0.9405,\n",
      "        1.0863, 1.0681, 0.9732, 0.9020, 0.9914, 0.9732, 1.3128, 0.9585, 0.9333,\n",
      "        0.9433, 0.8790, 1.1479, 0.9481, 1.0695, 0.9663, 0.9757, 1.0728, 0.8427,\n",
      "        0.9790, 1.0694, 1.0527, 1.0305, 0.9935, 0.9955, 0.9932, 1.0478, 0.9997,\n",
      "        0.8600, 0.8966, 0.9301, 0.9483, 0.8895, 1.1181, 1.0606],\n",
      "       grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "retreived_output_symbol_vector, m = embedding.decode(logits)\n",
    "print(retreived_output_symbol_vector, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1acd6b66-770e-42d1-b01a-cce2d9bd2523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([48505, 20110,  1108, 48019,    80, 19216,  9718,  1113,  4927,    66,\n",
       "        19216,  1448,  2122, 41530,   187,  4172,   246,   659, 10986, 30975,\n",
       "           80, 12931,   352, 14134,  2721,   258,  8830,    87,   826,    15,\n",
       "        17532,   729, 26798, 41070,  6575,   299,   266,  3737, 20889,   287,\n",
       "          512,   354,   250,   247,    70,   275, 16128,  2680,    74, 13679,\n",
       "           15,   209])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(52) over torch.Size([52])\n"
     ]
    }
   ],
   "source": [
    "o = embedding.decode(current_output_symbols[:, -1])[0]\n",
    "display(o)\n",
    "\n",
    "print(sum(o == retreived_output_symbol_vector), 'over', retreived_output_symbol_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4fe7568a-9319-4beb-b56c-89c8fd366f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### test single block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "370fac45-4707-43d5-88f8-df78ee1c931c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 1024]) torch.Size([3, 1024])\n",
      "torch.Size([4, 1024]) torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "print(input_sequence[3].shape, current_output_symbols[3].shape)\n",
    "print(input_sequence[3][0].shape, current_output_symbols[3][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d28e7b-29c7-4368-9111-360fd75ab9b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "01cd5f78-d3a8-4be2-952a-2db537b10110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153/156\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0 \n",
    "\n",
    "for batch_index in range(len(memo_input[0]['input_ids'])):\n",
    "    #print(\"input ids\", memo_input[0]['input_ids'][batch_index])\n",
    "    #print()\n",
    "    \n",
    "    for i in range(len(current_output_symbols[batch_index])):\n",
    "        #display(embedding.decode(input_sequence[batch_index][i]), embedding.decode(current_output_symbols[batch_index][i]))\n",
    "        true = embedding.decode(current_output_symbols[batch_index][i])[0].item()\n",
    "        \n",
    "        _, seq_encoding_for_the_last_layer  = layer.retrieve(input_sequence[batch_index][i].unsqueeze(0).unsqueeze(0))\n",
    "        \n",
    "        retreived_output_symbol_vector, m = embedding.decode(layer.directly_retrieve(seq_encoding_for_the_last_layer))\n",
    "        pred = retreived_output_symbol_vector.item()\n",
    "\n",
    "        total += 1\n",
    "        correct += pred == true\n",
    "\n",
    "print(f\"{correct}/{total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592772e2-6b27-4071-bd5f-a441876381fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b22599b-d21d-43bc-b728-dbadd0e4263d",
   "metadata": {},
   "source": [
    "### Check with batch size of 1 and output probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "30176822-1cf4-4b5e-8fbc-7e4375fdecab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2520,  310,  247, 1071,  323,  247, 1077, 2159, 2159, 3425,  273, 1249]]) tensor([[  310,   247,  1071,   323,   247,  1077,  2159,  2159,  3425,   273,\n",
      "          1249, 21761]])\n",
      "(tensor([[  323,  2159, 21761]]), tensor([[0.9441, 0.9547, 1.0388]]))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3, 4, 1024]), torch.Size([1, 3, 1024]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.get_text_batch_encoding(['this is a test for a very short short sequence of 12 tokens'])[0]\n",
    "input_ids, labels = memo_input['input_ids'], memo_input['labels']\n",
    "print(input_ids, labels)\n",
    "\n",
    "input_embeddings = embedding.encode(input_ids)\n",
    "#print(input_embeddings.shape)\n",
    "\n",
    "output_embeddings = embedding.encode(labels)\n",
    "#print(output_embeddings.shape)\n",
    "\n",
    "\n",
    "current_length = max_length\n",
    "\n",
    "current_length = int(current_length/h)\n",
    "input_sequence = input_embeddings.reshape((1, current_length, h, d))\n",
    "\n",
    "output_symbols = output_embeddings[:, [(x+1)*h-1 for x in range(0,current_length)]] ## the output symbol is always the same tokem?\n",
    "print(embedding.decode(output_symbols))\n",
    "input_sequence.shape, output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4968bbc-e2df-44ca-93ac-9610a1ab071c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[2520,  310,  247, 1071],\n",
       "          [ 323,  247, 1077, 2159],\n",
       "          [2159, 3425,  273, 1249]]]),\n",
       " tensor([[  323,  2159, 21761]]),\n",
       " tensor([[2520,  310,  247, 1071,  323,  247, 1077, 2159, 2159, 3425,  273, 1249]]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.decode(input_sequence)[0], embedding.decode(output_symbols)[0], input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cfaf35a-6ff8-4979-9727-cedcb78d8c9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 4, 1024])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ccc5bed4-5902-4f96-bab2-f1eefe5207c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1024])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_symbols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "813fecba-8575-4e2b-8271-e94af40c2600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeMoLayer(\n",
       "  (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "  (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "  (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1024])\n",
      "tensor([323]) tensor([0.9780], grad_fn=<MaxBackward0>)\n",
      "torch.Size([1, 1024])\n",
      "tensor([2159]) tensor([1.0270], grad_fn=<MaxBackward0>)\n",
      "torch.Size([1, 1024])\n",
      "tensor([21761]) tensor([1.1140], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "layer = MeMoLayer(d, h)\n",
    "display(layer)\n",
    "\n",
    "## update the input sequence for the next layer\n",
    "_, seq_encoding_for_the_last_layer = layer.memorize(input_sequence, output_symbols, is_last=False)\n",
    "layer.directly_memorize(seq_encoding_for_the_last_layer)\n",
    "\n",
    "for i in range(0,3):\n",
    "    _, seq_encoding_for_the_last_layer = layer.retrieve(input_sequence[0][i].unsqueeze(0).unsqueeze(0))\n",
    "    print(seq_encoding_for_the_last_layer.shape)\n",
    "                                                        \n",
    "    retreived_output_symbol_vector, m = embedding.decode(layer.directly_retrieve(seq_encoding_for_the_last_layer))\n",
    "    print(retreived_output_symbol_vector, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c89cd-cb85-4742-a214-c1fe1812e0de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80c3e709-edf1-4366-9766-ed6403ecedb9",
   "metadata": {},
   "source": [
    "## Test the entire MeMo model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6a73e8f4-a4d6-4dcf-9698-3c9853976b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo import MeMo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9113cb02-449d-4ff0-b0d4-0cf121004e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MeMoPyTorch.modelling_memo_tokenizer import MeMoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0a3e1627-b177-455c-9a81-7ab248fb1fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testo_di_prova.txt\") as my_first_text_f:\n",
    "    my_first_text = my_first_text_f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c58b7e91-677e-44f4-a738-93b3d3bb9ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPTNeoXTokenizer'. \n",
      "The class this function is called from is 'MeMoTokenizer'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting pad token and pad token id = <|endoftext|>, 0\n"
     ]
    }
   ],
   "source": [
    "max_length = 384\n",
    "print(max_length, h)\n",
    "tokenizer = MeMoTokenizer.from_pretrained(\"EleutherAI/gpt-neox-20b\", \n",
    "                                          padding_side='left', truncation_side='left', \n",
    "                                          max_length=max_length, head_number=h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6cd21d5d-2e4e-4b8d-aebc-b8f78421a038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 384])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memo_input = tokenizer.memo_heads_encode(my_first_text[0:10])\n",
    "memo_input[0]['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bacfc15c-56ea-49e3-9628-cec62cc9019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:0' #'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2e7021d0-26d9-448b-ba86-23c38c87499c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 4, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,h,l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c2b3fb1-8a1c-4678-8831-da82aeece4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeMo(\n",
       "  (encoder): MeMoEmbedding(50254, 1024, padding_idx=0)\n",
       "  (layers): ModuleList(\n",
       "    (0-2): 3 x MeMoLayer(\n",
       "      (W_v_single_head): ProjectionTokens(in_features=1024, out_features=256)\n",
       "      (Prj): ProjectionSequence((trasposed wrt saved one) in_features=4096, out_features=1024)\n",
       "      (CMM): CorrelationMatrixMemory(in_features=1024, out_features=1024)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MeMo(inner_dim=d, \n",
    "             num_of_heads=h, \n",
    "             num_of_layers=3, \n",
    "             chunk_length=max_length, \n",
    "             num_embeddings=tokenizer.vocab_size, \n",
    "             padding_idx=tokenizer.pad_token_id, \n",
    "             device=device) #MeMoModel\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81da7dce-28c9-4dcf-a6ba-3f7ea6a0ae3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b6ab2cc-10fc-4634-927d-8b2391baa8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "    def check_memorization(self, model, tokenizer, text, # device='cpu',\n",
    "                           starting_point=None):\n",
    "        if starting_point == None:\n",
    "            basic_block = model.h ** model.l\n",
    "        else:\n",
    "            basic_block = starting_point\n",
    "        \n",
    "        \n",
    "        input_ = tokenizer(my_first_text, padding='longest', truncation='do_not_truncate', max_length=None)\n",
    "        input_ = tokenizer.pad(input_, pad_to_multiple_of=basic_block)\n",
    "        input_ids = input_['input_ids']\n",
    "                \n",
    "        count = 0\n",
    "        correct = 0\n",
    "        max_length = tokenizer.max_length\n",
    "        (batch_size, number_of_tokens) = input_ids.shape\n",
    "\n",
    "        #print(f\"(batch_size, number_of_tokens) = {(batch_size, number_of_tokens)}\")\n",
    "        \n",
    "        for i in tqdm.tqdm(range(basic_block,  number_of_tokens - 1)):\n",
    "            text_tokens = input_ids[:, i - basic_block:i]\n",
    "            \n",
    "            (batch_size, number_of_tokens) = text_tokens.shape\n",
    "            \n",
    "            text_tokens = torch.concat((torch.zeros((batch_size, max_length-1-number_of_tokens), \n",
    "                                                    dtype=torch.int), \n",
    "                                        text_tokens), axis=1\n",
    "                                      )\n",
    "            \n",
    "            #print(i - basic_block, i)\n",
    "            out, max_value = model.retrieve(text_tokens)\n",
    "            #print(out, input_ids[:, i])\n",
    "            #print(out[0].item())\n",
    "            \n",
    "            count += batch_size\n",
    "            correct += torch.sum(out.to('cpu') == input_ids[:, i])\n",
    "        \n",
    "                           \n",
    "        return correct / count\n",
    "\n",
    "    def check_pretokenized(self, model, tokenizer, input_ids,# device='cpu',\n",
    "                           starting_point=None):\n",
    "        if starting_point == None:\n",
    "            basic_block = model.h ** model.l\n",
    "        else:\n",
    "            basic_block = starting_point\n",
    "                \n",
    "        count = 0\n",
    "        correct = 0\n",
    "        max_length = tokenizer.max_length\n",
    "        (batch_size, number_of_tokens) = input_ids.shape\n",
    "\n",
    "        #print(f\"(batch_size, number_of_tokens) = {(batch_size, number_of_tokens)}\")\n",
    "        \n",
    "        for i in tqdm.tqdm(range(basic_block,  number_of_tokens - 1)):\n",
    "            text_tokens = input_ids[:, i - basic_block:i]\n",
    "            \n",
    "            (batch_size, number_of_tokens) = text_tokens.shape\n",
    "            \n",
    "            text_tokens = torch.concat((torch.zeros((batch_size, max_length-1-number_of_tokens), \n",
    "                                                    dtype=torch.int), \n",
    "                                        text_tokens), axis=1\n",
    "                                      )\n",
    "            \n",
    "            #print(i - basic_block, i)\n",
    "            out, max_value = model.retrieve(text_tokens)\n",
    "            #print(out, input_ids[:, i])\n",
    "            #print(out[0].item())\n",
    "            \n",
    "            count += batch_size\n",
    "            correct += torch.sum(out.to('cpu') == input_ids[:, i])\n",
    "        \n",
    "                           \n",
    "        return correct / count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f8a2bd82-a24f-4274-a2bf-26170f8abfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:01<00:00, 200.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.9091)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MeMo(inner_dim=d, \n",
    "             num_of_heads=h, \n",
    "             num_of_layers=l, \n",
    "             chunk_length=max_length, \n",
    "             num_embeddings=tokenizer.vocab_size, \n",
    "             padding_idx=tokenizer.pad_token_id, \n",
    "             device=device)\n",
    "\n",
    "memo_input = tokenizer.get_text_batch_encoding([my_first_text]*8)\n",
    "model.memorize_text(memo_input)\n",
    "\n",
    "e = Evaluation()\n",
    "out = e.check_pretokenized(model, tokenizer, memo_input[0]['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c72f7371-61f8-4f80-b332-ec7d8703d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeMo embedding initilialization\n",
      "CMM pre learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:01<00:00, 201.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.8558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MeMo(inner_dim=d, \n",
    "             num_of_heads=h, \n",
    "             num_of_layers=l, \n",
    "             chunk_length=max_length, \n",
    "             num_embeddings=tokenizer.vocab_size, \n",
    "             padding_idx=tokenizer.pad_token_id, \n",
    "             device=device)\n",
    "print(\"CMM pre learning\")\n",
    "display(model.layers[0].CMM.weight)\n",
    "\n",
    "\n",
    "\n",
    "memo_input = tokenizer.get_text_batch_encoding([my_first_text]*8)\n",
    "(bs, ml) = memo_input[0]['input_ids'].shape\n",
    "\n",
    "for b in range(bs):\n",
    "    memo_single_input = {h: {k: memo_input[h][k][b].unsqueeze(0) for k in memo_input[h]} for h in memo_input}\n",
    "    #print(memo_single_input[0]['input_ids'].shape)\n",
    "\n",
    "    model.memorize_text(memo_single_input)\n",
    "\n",
    "e = Evaluation()\n",
    "out = e.check_pretokenized(model, tokenizer, memo_input[0]['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "67c1f7ed-02cd-4f13-aa01-e8821b11f302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0178e+00,  3.8739e-04,  1.7499e-02,  ..., -6.0468e-03,\n",
       "          1.1178e-02, -9.1373e-03],\n",
       "        [ 3.8739e-04,  1.0019e+00, -1.0599e-03,  ..., -2.0136e-03,\n",
       "          2.9460e-03, -2.7718e-02],\n",
       "        [ 1.7499e-02, -1.0599e-03,  9.5958e-01,  ..., -1.0601e-02,\n",
       "         -1.2269e-02,  7.5585e-03],\n",
       "        ...,\n",
       "        [-6.0468e-03, -2.0136e-03, -1.0601e-02,  ...,  9.8908e-01,\n",
       "          6.3645e-03, -2.5074e-02],\n",
       "        [ 1.1178e-02,  2.9460e-03, -1.2269e-02,  ...,  6.3645e-03,\n",
       "          1.0045e+00, -7.4022e-03],\n",
       "        [-9.1373e-03, -2.7718e-02,  7.5585e-03,  ..., -2.5074e-02,\n",
       "         -7.4022e-03,  1.0261e+00]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prj = model.layers[0].Prj.weight.detach().cpu()\n",
    "CMM = model.layers[0].CMM.weight.detach().cpu()\n",
    "\n",
    "Prj.T @ Prj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41935a13-0b0f-4b93-b129-0a1e88241fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0236, -0.0366, -0.0132,  ...,  0.0719,  0.0025, -0.0073],\n",
       "        [ 0.0307,  0.0299,  0.0235,  ...,  0.0044,  0.0144, -0.0217],\n",
       "        [ 0.0413, -0.0083,  0.0033,  ...,  0.0161,  0.0156, -0.0391],\n",
       "        ...,\n",
       "        [-0.0076,  0.0381,  0.0200,  ..., -0.0089,  0.0288, -0.0411],\n",
       "        [-0.0190, -0.0297, -0.0008,  ...,  0.0185, -0.0133, -0.0069],\n",
       "        [-0.0405, -0.0487, -0.0048,  ...,  0.0089, -0.0061,  0.0177]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d237416-54ea-4b21-8d19-84599ff9e34a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8ad99bb2-af43-4e42-a447-6871f4ee47f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:01<00:00, 199.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.8558)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = e.check_pretokenized(model, tokenizer, memo_input[0]['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "346e794d-b1c9-438e-b66f-14fd17c1ba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.forget_text(memo_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c4d5e5c-a117-4378-970a-d42b76a0ed12",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 319/319 [00:01<00:00, 201.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Degree of memorization: %f  tensor(0.0878)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = e.check_pretokenized(model, tokenizer, memo_input[0]['input_ids'])\n",
    "print(\"Degree of memorization: %f \", out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9e371-c48a-479a-8cec-fc87c9aaacdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
